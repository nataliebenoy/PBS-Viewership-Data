---
title: "Clustering with Anonymized PBS On-Demand Viewing Data"
author: "Natalie Benoy"
date: "7/27/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

### About this dataset:
This is a dataset containing on-demand streaming data of PBS programs by active donors of PBS Utah. Streaming data has been collected from the PBS Video App, for a period of time between December 2020 and March 2022. Variables include:

- Content.Channel (program streamed)
- Device
- Unique identifier variable (ID) associated with unique viewer email addresses (which have been removed for privacy reasons)

### Goals of this project:
The goal of this project was to use unsupervised learning, in this case clustering, to segment users by viewing behavior. In doing so, we hope to:

- learn more about PBS Utah member viewing trends
- obtain defined clusters into which new members can be assigned
- use the new cluster assignments to send targeted email communications to streaming members of PBS Utah, with program recommendations based on cluster assignment

### Load data and packages

```{r}
library(tidyverse)
library(ggplot2)

# Import cleaned and anonymized dataset, with unecessary, redundant, or personally identifiable variables like UID, Membership.ID, TP.Media.ID, CID, Title, First.Name, Last.Name, Email already removed.
# Remove row index generated by CSV import.
streaming <- read.csv("streaming_anon.csv")
streaming <- streaming[-1]

# Print the first 5 rows of the streaming dataset
head(streaming)
```

### Exploratory analysis
Which programs are most popular with PBS Utah streaming viewers? We'll take a look at the top program titles in descending order of total number of streams.

```{r}
# Take a look at top programs (truncated results)
streaming %>%
  group_by(Content.Channel) %>%
  summarize(n = n()) %>%
  arrange(desc(n))
```

```{r}
# Look at top programs again (less truncated results)
summary(streaming$Content.Channel)
```

We can see that both popular dramas (like All Creatures Great and Small, Grantchester, and Miss Scarlet and the Duke) and long-running series with a large quantity of episodes (PBS NewsHour, NOVA, Finding Your Roots) appear to be popular with PBS Utah on-demand viewers.

```{r}
# Visualizing the distribution of streams using a histogram
count_of_streams_by_program <- streaming %>%
  group_by(Content.Channel) %>%
  summarize(total_program_streams = n())

ggplot(count_of_streams_by_program, aes(x=total_program_streams)) + geom_histogram(binwidth = 2000) + labs(title = 'Distribution of streams by program')
```

Clearly, the distribution is very right-skewed, with the vast majority of programs being streamed less than 2,000 times during the 16-month period we are looking at. But just how right-skewed is it?

```{r}
# Basic summary statistics
# Just how right-skewed is the distribution of streams by program?
mean(count_of_streams_by_program$total_program_streams)
median(count_of_streams_by_program$total_program_streams)
```
With a mean number of 508 streams per program title and median number of only 5, we can see exactly how skewed streaming behavior is toward a select few program titles.

# Clustering by Genre
Now that we have a better understanding of our dataset, it's time to lay the groundwork for our unsupervised learning task â€” clustering. Clustering based on what genres of programs viewers like to watch seems like a resonable way to segment users by their viewing preferences. Genre information was pulled manually from pbs.org/video.

### Feature engineering
Now we'll map genre information to the top 50 programs.
If genre information had been included in the original dataset, or if PBS had an API for their backend media management system such that the genre information for each program could be scraped from the web, this section would have been far less tedious.

```{r}
# Creating new boolean "Genre" variables based on the top 50 programs ranked by total sum of streams

streaming_by_genre <- streaming %>%
  mutate(Drama = ifelse(Content.Channel %in% c("All Creatures Great and Small", "Grantchester", "Miss Scarlet & The Duke", "Unforgotten", "Atlantic Crossing", "Professor T", "Around the World in 80 Days", "Call the Midwife", "Downton Abbey", "Sanditon", "Seaside Hotel", "Frankie Drake Mysteries", "Vienna Blood", "Poldark", "Halifax: Retribution", "Baptiste", "Thou Shalt Not Kill", "BroadChurch", "Endeavour", "Roadkill", "Jamestown", "No Second Chance", "The Long Song", "Victoria", "Guilt", "Land Girls", "Us", "The Trouble With Maggie Cole", "The Indian Doctor", "RFDS: Royal Flying Doctor Service", "Line of Separation", "COBRA"), 1, 0),
         ScienceandNature = ifelse(Content.Channel %in% c("NOVA", "Nature"), 1, 0),
         Culture = ifelse(Content.Channel %in% c("Finding Your Roots", "Rick Steves' Europe", "This Is Utah", "Lidia Celebrates America"), 1, 0),
         ArtsandMusic = ifelse(Content.Channel %in% c("Great Performances", "Austin City Limits", "The Best of the Joy of Painting with Bob Ross", "Craft in America", "Inside the Met"), 1, 0),
         NewsandPublicAffairs = ifelse(Content.Channel %in% c("PBS NewsHour", "FRONTLINE", "Washington Week", "Amanpour and Company", "The Hinckley Report", "Utah Insight"), 1, 0),
         History = ifelse(Content.Channel %in% c("American Experience", "American Masters", "Secrets of the Dead", "Hemingway", "Muhammad Ali", "Utah History"), 1, 0),
         HomeandHowTo = ifelse(Content.Channel %in% c("This Old House", "Antiques Roadshow", "Ask This Old House"), 1, 0),
         Food = ifelse(Content.Channel %in% c("The Great British Baking Show", "Christopher Kimball's Milk Street Television", "Lidia's Kitchen", "America's Test Kitchen", "A Chef's Life", "Simply Ming", "Cook's Country"), 1, 0),
         IndieFilms = ifelse(Content.Channel %in% c("Independent Lens", "POV", "America Reframed"), 1, 0))

# Look at the new dataset, checking to make sure new variables were created correctly
summary(streaming_by_genre)

# Check for rows where any of the above programs were not watched
count(streaming_by_genre[rowSums(streaming_by_genre[4:12]) == 0,])
```

Looks like 247,203 streams were of programs not contained in the top 50.
In other words, the top 50 programs above accounted for 78% of all streaming during this time period.

```{r}
# Update streaming_by_genre dataset to reflect only viewers who have watched at least 1 of the above programs
streaming_by_genre <- streaming_by_genre[rowSums(streaming_by_genre[4:12]) > 0,]
```

### Aggregating by unique user identifier (ID)
The source data consists of rows of individual streams, not rows of individual users. To isolate streams by unique user, we need to aggregate by each user's unique identifier (in this case, the ID column).

```{r}
# Remove Content.Channel column, also Device column (could consider keeping it in for future iterations); would need to turn it into a dummy variable
streaming_by_genre <- streaming_by_genre[c(-1,-2)]

# Aggregate by ID
streaming_by_genre <- streaming_by_genre %>%
  group_by(ID) %>%
  summarise_each(funs(max)) 

# Print the first 5 rows of the new dataset to make sure everything looks right
head(streaming_by_genre)
```

### Clustering
Now we'll create the cluster assignments and print the cluster centers.

```{r}
# Isolate only the programs to use for clustering (remove ID column)
streaming_genres <- streaming_by_genre[-1]

# Create clusters
set.seed(123)
genre.clusters <- kmeans(streaming_genres, 7)
genre.clusters$size
genre.clusters$centers
```

### So what did we learn?
- Most groups (excepting Groups 3 & 7) are big on Drama. From this we can reasonably conclude that PBS Utah viewers are big fans of watching dramas on demand.
- Group 7 is for history buffs. They don't watch drama at all, but there's some overlap with Science & Nature and News.
- Group 6 is for Home & How-To people. There's strong crossover with the Drama, Science & Nature and History genres.
- Group 5 is interested in Culture and Drama, and scores lower on Science & Nature and History.
- Group 4 watches absolutely everything. They score high across the board, and also score the highest on Arts & Music and Food programming. Let's call them PBS Superfans.
- Group 3 has no interest in Drama or History. They're casual viewers of Science & Nature and News, but not super fans of any genre.
- Group 2 is for drama lovers and drama lovers only. They score low across all other genres, and scored the lowest among the otherwise-popular Science & Nature and History genres.
- Group 1 has no interest in Home & How-To. They score reasonably high on History, News, Science & Nature and Drama.

#### Determining the Number of Clusters
```{r}
# Use the elbow method to determine the optimal value of k
# Start by decreasing the sample size to make it computationally easier
index <- sample(1:nrow(streaming_genres), floor(nrow(streaming_genres)*0.05))
streaming.subset <- streaming_genres[index,]
wss <- function(k){
  kmeans(streaming.subset, k, nstart = 10)$tot.withinss
}
wss(5)
kValues <- 2:15
wssvalues <- unlist(lapply(kValues, wss))
wssvalues

# Plot values against k (making the elbow plot)
plot(kValues, wssvalues)
```

It looks as though 6 or 7 values of k is optimal. However, if we intend to use our new clusters as audience segments, each to receive its own targeted email communication, a good question to ask is: How many different email iterations so we really want to send? If the answer is "fewer emails," then a smaller value of k may be more appropriate for the business use case.

```{r}
# finally, add the cluster assignments back into the dataset
streaming_by_genre$cluster <- genre.clusters$cluster

head(streaming_by_genre)
```

## Bonus Section: Clustering by Program Instead of Genre
Can we extract some meaningful insights by creating clusters based on program, and not genre?

```{r}
# create boolean variables for each of the top 50 programs
streaming_by_program <- streaming %>%
  mutate(AllCreatures = ifelse(Content.Channel == "All Creatures Great and Small", 1, 0),
         NewsHour = ifelse(Content.Channel == "PBS NewsHour", 1, 0),
         NOVA = ifelse(Content.Channel == "NOVA", 1, 0),
         FindingYourRoots = ifelse(Content.Channel == "Finding Your Roots", 1, 0),
         Grantchester = ifelse(Content.Channel == "Grantchester", 1, 0),
         MissScarlet = ifelse(Content.Channel == "Miss Scarlet & The Duke", 1, 0),
         Unforgotten = ifelse(Content.Channel == "Unforgotten", 1, 0),
         AtlanticCrossing = ifelse(Content.Channel == "Atlantic Crossing", 1, 0),
         AntiquesRoadshow = ifelse(Content.Channel == "Antiques Roadshow", 1, 0),
         ProfessorT = ifelse(Content.Channel == "Professor T", 1, 0),
         Nature = ifelse(Content.Channel == "Nature", 1, 0),
         AroundTheWorldin80Days = ifelse(Content.Channel == "Around the World in 80 Days", 1, 0),
         CallTheMidwife = ifelse(Content.Channel == "Call the Midwife", 1, 0),
         DowntonAbbey = ifelse(Content.Channel == "Downton Abbey", 1, 0),
         FRONTLINE = ifelse(Content.Channel == "FRONTLINE", 1, 0),
         Sanditon = ifelse(Content.Channel == "Sanditon", 1, 0),
         SeasideHotel = ifelse(Content.Channel == "Seaside Hotel", 1, 0),
         FrankieDrake = ifelse(Content.Channel == "Frankie Drake Mysteries", 1, 0),
         ViennaBlood = ifelse(Content.Channel == "Vienna Blood", 1, 0),
         AmericanExperience = ifelse(Content.Channel == "American Experience", 1, 0),
         Poldark = ifelse(Content.Channel == "Poldark", 1, 0),
         GreatPerformances = ifelse(Content.Channel == "Great Performances", 1, 0),
         AmericanMasters = ifelse(Content.Channel == "American Masters", 1, 0),
         SecretsoftheDead = ifelse(Content.Channel == "Secrets of the Dead", 1, 0),
         HalifaxRetribution = ifelse(Content.Channel == "Halifax: Retribution", 1, 0),
         Baptiste = ifelse(Content.Channel == "Baptiste", 1, 0),
         ThouShaltNotKill = ifelse(Content.Channel == "Thou Shalt Not Kill", 1, 0),
         Broadchurch = ifelse(Content.Channel == "Broadchurch", 1, 0),
         Endeavour = ifelse(Content.Channel == "Endeavour", 1, 0),
         ThisOldHouse = ifelse(Content.Channel == "This Old House", 1, 0),
         RickSteves = ifelse(Content.Channel == "Rick Steves' Europe", 1, 0),
         IndependentLens = ifelse(Content.Channel == "Independent Lens", 1, 0),
         AustinCityLimits = ifelse(Content.Channel == "Austin City Limits", 1, 0),
         GreatBritishBakingShow = ifelse(Content.Channel == "The Great British Baking Show", 1, 0),
         Hemingway = ifelse(Content.Channel == "Hemingway", 1, 0),
         Roadkill = ifelse(Content.Channel == "Roadkill", 1, 0),
         Jamestown = ifelse(Content.Channel == "Jamestown", 1, 0),
         NoSecondChance = ifelse(Content.Channel == "No Second Chance", 1, 0),
         TheLongSong = ifelse(Content.Channel == "The Long Song", 1, 0),
         Victoria = ifelse(Content.Channel == "Victoria", 1, 0),
         Guilt = ifelse(Content.Channel == "Guilt", 1, 0),
         LandGirls = ifelse(Content.Channel == "Land Girls", 1, 0),
         Us = ifelse(Content.Channel == "Us", 1, 0),
         TroubleWithMaggieCole = ifelse(Content.Channel == "The Trouble With Maggie Cole", 1, 0),
         TheIndianDoctor = ifelse(Content.Channel == "The Indian Doctor", 1, 0),
         RoyalFlyingDoctorService = ifelse(Content.Channel == "RFDS: Royal Flying Doctor Service", 1, 0),
         MuhammadAli = ifelse(Content.Channel == "Muhammad Ali", 1, 0),
         UtahHistory = ifelse(Content.Channel == "Utah History", 1, 0),
         LineofSeparation = ifelse(Content.Channel == "Line of Separation", 1, 0),
         WashingtonWeek = ifelse(Content.Channel == "Washington Week", 1, 0),
         COBRA = ifelse(Content.Channel == "COBRA", 1, 0))
 
# Look at new dataset, check to make sure new variables were created correctly
summary(streaming_by_program)

# check for rows where programs other than those in the top 50 programs seen above were streamed
count(streaming_by_program[rowSums(streaming_by_program[4:54]) == 0,])

# update streaming_by_program dataset to reflect only viewers who have watched at least 1 of the above programs
streaming_by_program <- streaming_by_program[rowSums(streaming_by_program[4:54]) > 0,]
```

### Aggregating by unique user identifier (ID)
The source data consists of rows of individual streams, not rows of individual users. To isolate streams by unique user, we need to aggregate by each user's unique identifier (in this case, the ID column).

```{r}
# Remove Content.Channel column, also Device column (could consider keeping it in for future iterations)
# would need to turn it into a dummy variable
streaming_by_program <- streaming_by_program[c(-1,-2)]

# aggregate by ID
streaming_by_program <- streaming_by_program %>%
  group_by(ID) %>%
  summarise_each(funs(max)) 

# check to make sure everything looks right
head(streaming_by_program)
```

### Clustering
Now we'll create the cluster assignments and print the cluster centers.

```{r}
# isolate only the programs to use for clustering (remove ID)
streaming_programs <- streaming_by_program[-1]

# run cluster
set.seed(123)
clusters <- kmeans(streaming_programs, 5)
clusters$size
clusters$centers
```

Notice that the cluster centers become much less easy to understand when we've drilled down to the program level instead of the higher-order genre level. Perhaps market-basket analysis would be better here.

#### Determining the Number of Clusters
```{r}
# Use elbow method to determine the optimal value of k
# start by decreasing the sample size to make it computationally easier
index <- sample(1:nrow(streaming_programs), floor(nrow(streaming_programs)*0.05))
streaming.subset <- streaming_programs[index,]
wss <- function(k){
  kmeans(streaming.subset, k, nstart = 10)$tot.withinss
}
wss(5)
kValues <- 2:15
wssvalues <- unlist(lapply(kValues, wss))
wssvalues

# plot values against k (making the elbow plot)
plot(kValues, wssvalues)
```

## Conclusions and Future Iterations
We have now successfully segmented the PBS Utah donor audience by their viewing behavior. With cluster assignments added back in to the dataset, these viewers could then be served more targeted email communications based on their assigned cluster, either when grouped by genre or by program.

However, the lack of readily available genre information for each program title means that a number of viewers would be left without cluster assignments. As there are thousands of unique program titles available through the PBS Video App, manually adding genre information program by program is not a feasible solution. More information is needed from PBS for this project to truly be considered complete.

