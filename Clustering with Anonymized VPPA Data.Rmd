---
title: "Clustering with Anonymized PBS On-Demand Viewing Data"
author: "Natalie Benoy"
date: "7/27/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

### About this dataset:
#### This is a dataset of streams of PBS programs by logged-in viewers localized to their local station on a variety of devices, for a period of time between late 2020 and early 2022. Variables include Content.Channel (program streamed), Device, and a unique identifier variable (ID) generated from viewer email addresses (removed for privacy).

### Load data and packages

```{r}
library(tidyverse)

# import cleaned and anonymized dataset, with unecessary, redundant, or personally identifiable variables like UID, Membership.ID, TP.Media.ID, CID, Title, First.Name, Last.Name, Email already removed.
# Remove row index generated by CSV import.
streaming <- read.csv("streaming_anon.csv")
streaming <- streaming[-1]
```

### Look at top programs by # of streams

```{r}
# take a look at top programs (truncated results)
streaming %>%
  group_by(Content.Channel) %>%
  summarize(n = n()) %>%
  arrange(desc(n))

# look at top programs (less truncated results)
summary(streaming$Content.Channel)
```

# Clustering by Genre

### Feature engineering

```{r}
# manually recategorizing the top 50 programs (or as many programs as I feel like) (aka the long and annoying part that I wouldn't have to do if PBS would just give us the genre information)

streaming_by_genre <- streaming %>%
  mutate(Drama = ifelse(Content.Channel %in% c("All Creatures Great and Small", "Grantchester", "Miss Scarlet & The Duke", "Unforgotten", "Atlantic Crossing", "Professor T", "Around the World in 80 Days", "Call the Midwife", "Downton Abbey", "Sanditon", "Seaside Hotel", "Frankie Drake Mysteries", "Vienna Blood", "Poldark", "Halifax: Retribution", "Baptiste", "Thou Shalt Not Kill", "BroadChurch", "Endeavour", "Roadkill", "Jamestown", "No Second Chance", "The Long Song", "Victoria", "Guilt", "Land Girls", "Us", "The Trouble With Maggie Cole", "The Indian Doctor", "RFDS: Royal Flying Doctor Service", "Line of Separation", "COBRA"), 1, 0),
         ScienceandNature = ifelse(Content.Channel %in% c("NOVA", "Nature"), 1, 0),
         Culture = ifelse(Content.Channel %in% c("Finding Your Roots", "Rick Steves' Europe", "This Is Utah", "Lidia Celebrates America"), 1, 0),
         ArtsandMusic = ifelse(Content.Channel %in% c("Great Performances", "Austin City Limits", "The Best of the Joy of Painting with Bob Ross", "Craft in America", "Inside the Met"), 1, 0),
         NewsandPublicAffairs = ifelse(Content.Channel %in% c("PBS NewsHour", "FRONTLINE", "Washington Week", "Amanpour and Company", "The Hinckley Report", "Utah Insight"), 1, 0),
         History = ifelse(Content.Channel %in% c("American Experience", "American Masters", "Secrets of the Dead", "Hemingway", "Muhammad Ali", "Utah History"), 1, 0),
         HomeandHowTo = ifelse(Content.Channel %in% c("This Old House", "Antiques Roadshow", "Ask This Old House"), 1, 0),
         Food = ifelse(Content.Channel %in% c("The Great British Baking Show", "Christopher Kimball's Milk Street Television", "Lidia's Kitchen", "America's Test Kitchen", "A Chef's Life", "Simply Ming", "Cook's Country"), 1, 0),
         IndieFilms = ifelse(Content.Channel %in% c("Independent Lens", "POV", "America Reframed"), 1, 0))

# look at new dataset, check to make sure new variables were created correctly
summary(streaming_by_genre)
```

### Aggregating by unique user identifier (ID)

```{r}
# remove Content.Channel column, also Device column (could consider keeping it in for future iterations); would need to turn it into a dummy variable
streaming_by_genre <- streaming_by_genre[c(-1,-2)]

# aggregate by ID
streaming_by_genre <- streaming_by_genre %>%
  group_by(ID) %>%
  summarise_each(funs(max)) 

# check to make sure everything looks right
head(streaming_by_genre)
```

### Clustering

```{r}
# isolate only the programs to use for clustering (remove ID)
streaming_genres <- streaming_by_genre[-1]

# run cluster
set.seed(123)
genre.clusters <- kmeans(streaming_genres, 7)
genre.clusters$size
genre.clusters$centers

# ok, so what did we learn here:
# EVERYONE watches Drama (surprise!)
# group 7 watches EVERYTHING
# the only people who care about Food are the people who watch literally everything (group 7)
# group 6 (Arts & Music people) are ok with Drama, sort of ok with Culture, don't really care about anything else
# group 5 (Indie Film people) are cool with Science & Nature, History
# group 4 (Home & How-To people) dgaf about News, are sort of interested in Arts & Music, Culture, History, Science
# group 3 (Culture people) dgaf about Indie Films, are cool with History, News & Science
# group 2 dgaf about Culture & Indie Films, like Science, History & News
# group 1 is confusing. They like Drama, and sample tiny bits of everything else (except Arts & Music)

# Use elbow method to determine the optimal value of k
# start by decreasing the sample size to make it computationally easier
index <- sample(1:nrow(streaming_genres), floor(nrow(streaming_genres)*0.05))
streaming.subset <- streaming_genres[index,]
wss <- function(k){
  kmeans(streaming.subset, k, nstart = 10)$tot.withinss
}
wss(5)
kValues <- 2:15
wssvalues <- unlist(lapply(kValues, wss))
wssvalues

# plot values against k (we're making the elbow plot)
plot(kValues, wssvalues)

# looks like maybe 7 or 8 values of k is optimal? Also depends on how many email iterations we'd really want to send?

# finally, add the cluster assignments back into the dataset
streaming_by_genre$cluster <- genre.clusters$cluster
```

# Clustering by Program Instead of Genre (for fun) (less useful)

```{r}
# create boolean variables for each of the top 50 programs
streaming_by_program <- streaming %>%
  mutate(AllCreatures = ifelse(Content.Channel == "All Creatures Great and Small", 1, 0),
         NewsHour = ifelse(Content.Channel == "PBS NewsHour", 1, 0),
         NOVA = ifelse(Content.Channel == "NOVA", 1, 0),
         FindingYourRoots = ifelse(Content.Channel == "Finding Your Roots", 1, 0),
         Grantchester = ifelse(Content.Channel == "Grantchester", 1, 0),
         MissScarlet = ifelse(Content.Channel == "Miss Scarlet & The Duke", 1, 0),
         Unforgotten = ifelse(Content.Channel == "Unforgotten", 1, 0),
         AtlanticCrossing = ifelse(Content.Channel == "Atlantic Crossing", 1, 0),
         AntiquesRoadshow = ifelse(Content.Channel == "Antiques Roadshow", 1, 0),
         ProfessorT = ifelse(Content.Channel == "Professor T", 1, 0),
         Nature = ifelse(Content.Channel == "Nature", 1, 0),
         AroundTheWorldin80Days = ifelse(Content.Channel == "Around the World in 80 Days", 1, 0),
         CallTheMidwife = ifelse(Content.Channel == "Call the Midwife", 1, 0),
         DowntonAbbey = ifelse(Content.Channel == "Downton Abbey", 1, 0),
         FRONTLINE = ifelse(Content.Channel == "FRONTLINE", 1, 0),
         Sanditon = ifelse(Content.Channel == "Sanditon", 1, 0),
         SeasideHotel = ifelse(Content.Channel == "Seaside Hotel", 1, 0),
         FrankieDrake = ifelse(Content.Channel == "Frankie Drake Mysteries", 1, 0),
         ViennaBlood = ifelse(Content.Channel == "Vienna Blood", 1, 0),
         AmericanExperience = ifelse(Content.Channel == "American Experience", 1, 0),
         Poldark = ifelse(Content.Channel == "Poldark", 1, 0),
         GreatPerformances = ifelse(Content.Channel == "Great Performances", 1, 0),
         AmericanMasters = ifelse(Content.Channel == "American Masters", 1, 0),
         SecretsoftheDead = ifelse(Content.Channel == "Secrets of the Dead", 1, 0),
         HalifaxRetribution = ifelse(Content.Channel == "Halifax: Retribution", 1, 0),
         Baptiste = ifelse(Content.Channel == "Baptiste", 1, 0),
         ThouShaltNotKill = ifelse(Content.Channel == "Thou Shalt Not Kill", 1, 0),
         Broadchurch = ifelse(Content.Channel == "Broadchurch", 1, 0),
         Endeavour = ifelse(Content.Channel == "Endeavour", 1, 0),
         ThisOldHouse = ifelse(Content.Channel == "This Old House", 1, 0),
         RickSteves = ifelse(Content.Channel == "Rick Steves' Europe", 1, 0),
         IndependentLens = ifelse(Content.Channel == "Independent Lens", 1, 0),
         AustinCityLimits = ifelse(Content.Channel == "Austin City Limits", 1, 0),
         GreatBritishBakingShow = ifelse(Content.Channel == "The Great British Baking Show", 1, 0),
         Hemingway = ifelse(Content.Channel == "Hemingway", 1, 0),
         Roadkill = ifelse(Content.Channel == "Roadkill", 1, 0),
         Jamestown = ifelse(Content.Channel == "Jamestown", 1, 0),
         NoSecondChance = ifelse(Content.Channel == "No Second Chance", 1, 0),
         TheLongSong = ifelse(Content.Channel == "The Long Song", 1, 0),
         Victoria = ifelse(Content.Channel == "Victoria", 1, 0),
         Guilt = ifelse(Content.Channel == "Guilt", 1, 0),
         LandGirls = ifelse(Content.Channel == "Land Girls", 1, 0),
         Us = ifelse(Content.Channel == "Us", 1, 0),
         TroubleWithMaggieCole = ifelse(Content.Channel == "The Trouble With Maggie Cole", 1, 0),
         TheIndianDoctor = ifelse(Content.Channel == "The Indian Doctor", 1, 0),
         RoyalFlyingDoctorService = ifelse(Content.Channel == "RFDS: Royal Flying Doctor Service", 1, 0),
         MuhammadAli = ifelse(Content.Channel == "Muhammad Ali", 1, 0),
         UtahHistory = ifelse(Content.Channel == "Utah History", 1, 0),
         LineofSeparation = ifelse(Content.Channel == "Line of Separation", 1, 0),
         WashingtonWeek = ifelse(Content.Channel == "Washington Week", 1, 0),
         COBRA = ifelse(Content.Channel == "COBRA", 1, 0))
 
# look at new dataset, check to make sure new variables were created correctly
summary(streaming_by_program)
```

### Aggregating by unique user identifier (ID)

```{r}
# remove Content.Channel column, also Device column (could consider keeping it in for future iterations)
# would need to turn it into a dummy variable
streaming_by_program <- streaming_by_program[c(-1,-2)]

# aggregate by ID
streaming_by_program <- streaming_by_program %>%
  group_by(ID) %>%
  summarise_each(funs(max)) 

# check to make sure everything looks right
head(streaming_by_program)
```

### Clustering

```{r}
# isolate only the programs to use for clustering (remove ID)
streaming_programs <- streaming_by_program[-1]

# run cluster
set.seed(123)
clusters <- kmeans(streaming_programs, 5)
clusters$size
clusters$centers

# Use elbow method to determine the optimal value of k
# start by decreasing the sample size to make it computationally easier
index <- sample(1:nrow(streaming_programs), floor(nrow(streaming_programs)*0.05))
streaming.subset <- streaming_programs[index,]
wss <- function(k){
  kmeans(streaming.subset, k, nstart = 10)$tot.withinss
}
wss(5)
kValues <- 2:15
wssvalues <- unlist(lapply(kValues, wss))
wssvalues

# plot values against k (we're making the elbow plot)
plot(kValues, wssvalues)
```

